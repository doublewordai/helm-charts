# Default values for takeoff.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []

# This is to override the chart name.
nameOverride: ""
fullnameOverride: ""

# This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

controller:
  # This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
  image:
    repository: tytn/takeoff-pro
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "0.22.0-rc15-cpu"

  config:
    # allowRemoteImages: false, // Whether to allow the user to specify url image requests
    # readerMessageTimeoutMs: 500, // How long between tokens before we timeout a reader.
    # reservedConsumers: "".to_string(), // Which consumers groups should buffer requests, rather than rejecting them
    # maxPromptStringBytes: 150000, // The maximum size of a prompt, in bytes
    # maxUserBatchSize: 1000, // The maximum allowed user batch size
    # bodySizeLimitBytes: 1024 * 1024 * 2, // The maximum body size
    # heartbeatCheckInterval: 1, // How frequently to check for dead readers. 0 means never

  env:
  # This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
  replicaCount: 1

  # This is for setting Kubernetes Annotations to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  # This is for setting Kubernetes Labels to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  podSecurityContext:
    {}
    # fsGroup: 2000

  securityContext:
    {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  ports:
    - containerPort: 3000
      protocol: TCP
      name: inference
    - containerPort: 3001
      protocol: TCP
      name: management
    - containerPort: 3003
      protocol: TCP
      name: openai
    - containerPort: 3005
      protocol: TCP
      name: internal

  # This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
  service:
    # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
    type: ClusterIP
    # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
    ports:
      - port: 80
        targetPort: inference
        protocol: TCP
        name: http
      - port: 3001
        protocol: TCP
        name: management
      - port: 3003
        protocol: TCP
        name: openai
      - port: 3005
        protocol: TCP
        name: internal

  # This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    enabled: false
    className: ""
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources:
    {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  livenessProbe:
    {}
    # httpGet:
    #   path: /healthz
    #   port: inference
  readinessProbe:
    {}
    # httpGet:
    #   path: /healthz
    #   port: inference

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

  exportPrometheusMetrics: false

# The application template sets the base values for all the deployed takeoff applications.
# An application is one or more replicas of a given model.
applicationTemplate:
  # This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
  image:
    repository: tytn/takeoff-pro
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "0.22.0-rc15-gpu"
  # The config of the reader that will be deployed in this application.
  # Values are ones from the docs, with snake case replaced with camelcase
  env:
  readerConfig:
    modelName: "TitanML/dummy_model"
    device: "cpu"
    consumerGroup: "primary"
    # accessToken: Option<String>, # The access token, to use when downloading from huggingface
    # logLevel: Option<String>, # The reader log level. Default is INFO
    # cudaVisibleDevices: Option<String>, # Comma separated list of cuda devices that should be visible to the reader. Defaults to the first one.
    # maxBatchSize: Option<int>, # The maximum batch size that the reader should process at one time.
    # tensorParallel: Option<int>, # How many GPUs to use.
    # quantType: Option<String>, The quant type to use
    # maxSequenceLength: Option<int>, # The maximum sequence length to constrain the system to
    # disableCudaGraph: Option<int>, # Whether to disable cuda graphs
    # cudaGraphCacheCapacity: Option<int>, # How many cuda graphs to store
    # pageCacheSize: Option<String> # The page cache size. Can be a size ("10MB", 5GB"), or a percentage ("90%"). Recommend max. of 90%.
    # prefillChunkSize: Option<int> # The maximum number of tokens in a prefill chunk.
    # quantizeCacheBits: Option<int> # Whether (and to what bitwidth) to quantize the cache
    # ssdCacheSize: Option<int> # How large the SSD cache should be in bytes
    # constrainedDecodingBackend: Option<String>, # The constrained decoding backend. Options are ["lmfe", "outlines", "all", "none"]
    # lmfeMaxConsecutiveWhitespaces: Option<int>, # Configuration parameter for LMFE
    # readerLogAsJson: Option<String>, # Whether to output json formatted logs
    # loras: Option<String>, # The loras to load on this reader.
    # enableDocumentProcessing: Option<bool>, # Whether to configure this reader for document processing.

  # This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
  replicaCount: 1

  # This is for setting Kubernetes Annotations to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  # This is for setting Kubernetes Labels to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  podSecurityContext:
    {}
    # fsGroup: 2000

  securityContext:
    {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  ports:
    - containerPort: 3000
      protocol: TCP
      name: inference
    - containerPort: 3001
      protocol: TCP
      name: management
    - name: openai
      containerPort: 3003
      protocol: TCP
    - containerPort: 3005
      protocol: TCP
      name: internal

  # This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
  service:
    # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
    type: ClusterIP
    # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
    ports:
      - port: 80
        targetPort: inference
        protocol: TCP
        name: http
      - port: 3001
        protocol: TCP
        name: management
      - port: 3003
        protocol: TCP
        name: openai
      - port: 3005
        protocol: TCP
        name: internal

  # This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    enabled: false
    className: ""
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources:
    {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  livenessProbe:
    # httpGet:
    #   path: /healthz
    #   port: inference
  readinessProbe:
    # httpGet:
    #   path: /healthz
    #   port: inference

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # This section is for setting up triggers in a metrics server and Horizontal Pod Autoscaler to dynamically scale the application.
  # We use KEDA for this, more information can be found here: https://keda.sh/docs/concepts/scaling-deployments/
  scaling:
    enabled: false
    annotations:
    # scaledobject.keda.sh/transfer-hpa-ownership: "true"     # Optional. Use to transfer an existing HPA ownership to this ScaledObject
    # validations.keda.sh/hpa-ownership: "true"               # Optional. Use to disable HPA ownership validation on this ScaledObject
    # autoscaling.keda.sh/paused: "true"                      # Optional. Use to pause autoscaling of objects explicitly
    spec:
      pollingInterval: 30 # Optional. Default: 30 seconds
      initialCooldownPeriod: 0 # Optional. Default: 0 seconds
      cooldownPeriod: 300 # Optional. Default: 300 seconds
      idleReplicaCount: 0 # Optional. Default: ignored, must be less than minReplicaCount
      minReplicaCount: 1 # Optional. Default: 0
      maxReplicaCount: 100 # Optional. Default: 100
      # fallback:                                                 # Optional. Section to specify fallback options
      #   failureThreshold: 3                                     # Mandatory if fallback section is included
      #   replicas: 6                                             # Mandatory if fallback section is included
      advanced: # Optional. Section to specify advanced options
        restoreToOriginalReplicaCount: false # Optional. Default: false
        horizontalPodAutoscalerConfig: # Optional. Section to specify HPA related options
          behavior: # Optional. Use to modify HPA's scaling behavior
            scaleDown:
              stabilizationWindowSeconds: 300
              policies:
                - type: Pods
                  value: 1
                  periodSeconds: 300
            scaleUp:
              stabilizationWindowSeconds: 300
              policies:
                - type: Pods
                  value: 1
                  periodSeconds: 300
      # These triggers are used to scale the application based on metrics from a provider. We choose to use Prometheus to hold our metrics you can find the specification for a
      # Prometheus trigger here: https://keda.sh/docs/scalers/prometheus/. The first trigger is used to move between the minReplicaCount and maxReplicaCount, the second trigger is
      # used to scale to idleReplicaCount.
      triggers:
        # Trigger that scales if the time a request spends in the queue is greater than 10 seconds
        - type: prometheus
          metadata:
            name: queue_size_trigger
            serverAddress: http://prometheus-operated.monitoring.svc.cluster.local:9090/ # Replace with the address of the cluster Prometheus server
            query: queue_time{job=~".*-controller", quantile="1", consumer_group="primary"} # Replace consumer_group with the consumerGroup set above for this application
            threshold: "1"
        # Trigger that scales to zero if there are no requests in the last minute
        - type: prometheus
          metadata:
            name: scaling_to_zero_trigger
            serverAddress: http://prometheus-operated.monitoring.svc.cluster.local:9090/ # Replace with the address of the cluster Prometheus server
            query: rate(http_pre_handler_requests_total{job=~".*-controller", path=~".*generate.*"}[1m]) # Replace consumer_group with the consumerGroup set above for this application
            activationThreshold: "0"
            threshold: "1000000"

# Use this section to deploy your takeoff applications
applications:
  {}
  # Note; application names have to be url safe!
  # dummy:
  #   resources:
  #     {}
